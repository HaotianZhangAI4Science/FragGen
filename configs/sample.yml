data:
  data_name: 'test'
  dataset:  # test dataset
    name: pl
    path: ./data/crossdocked_pocket10
    split: ./data/split_by_name.pt

model:
    checkpoint: ./ckpt/val_81.pt

sample:
  seed: 2020
  mask_init: True
  num_samples: 1000 # the maximum number of samples to generate
  beam_size: 500 # beam size is the maximum number of data in the queue, however, with less queue_same_smi_tolorance, it is hard to reach the beam size
  max_steps: 50 # the maximum number of global steps to take
  
  threshold: # the threshold for the first step, low threshold means better diversity, but consumes more time
    focal_threshold: 0.2
    pos_threshold: 0.2
    element_threshold: 0.25
  
  initial_num_steps: 3 # treat the (initial_num_steps) as the initial steps
  next_threshold: # the threshold for following step, low threshold means better diversity, but consumes more time
      focal_threshold: 0.2
      pos_threshold: 0.2
      element_threshold: 0.25
  
  queue_same_smi_tolorance: 3 # high tolerance means better diversity, but consumes more time 